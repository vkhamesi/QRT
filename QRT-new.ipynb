{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train_data = pd.read_csv('X_train.csv', index_col=0)\n",
    "train_labels = pd.read_csv('y_train.csv', index_col=0)\n",
    "test_data = pd.read_csv('X_test.csv', index_col=0)\n",
    "additionnal_data = pd.read_csv('supplementary_data_Vkoyn8z.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13414cfdb433428383506bd27519e217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Additionnal data \n",
    "CLASS_1 = [] \n",
    "CLASS_2 = []\n",
    "CLASS_3 = []\n",
    "CLASS_4 = []\n",
    "for element in tqdm(train_data[\"ID_TARGET\"].values):\n",
    "    CLASS_1.append(additionnal_data.loc[element][\"CLASS_LEVEL_1\"])\n",
    "    CLASS_2.append(additionnal_data.loc[element][\"CLASS_LEVEL_2\"])\n",
    "    CLASS_3.append(additionnal_data.loc[element][\"CLASS_LEVEL_3\"])\n",
    "    CLASS_4.append(additionnal_data.loc[element][\"CLASS_LEVEL_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"CLASS_LEVEL_1\"] = CLASS_1\n",
    "train_data[\"CLASS_LEVEL_2\"] = CLASS_2\n",
    "train_data[\"CLASS_LEVEL_3\"] = CLASS_3\n",
    "train_data[\"CLASS_LEVEL_4\"] = CLASS_4\n",
    "train_data[\"RET_TARGET\"] = train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_DAY</th>\n",
       "      <th>RET_216</th>\n",
       "      <th>RET_238</th>\n",
       "      <th>RET_45</th>\n",
       "      <th>RET_295</th>\n",
       "      <th>RET_230</th>\n",
       "      <th>RET_120</th>\n",
       "      <th>RET_188</th>\n",
       "      <th>RET_260</th>\n",
       "      <th>RET_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RET_193</th>\n",
       "      <th>RET_95</th>\n",
       "      <th>RET_162</th>\n",
       "      <th>RET_297</th>\n",
       "      <th>ID_TARGET</th>\n",
       "      <th>CLASS_LEVEL_1</th>\n",
       "      <th>CLASS_LEVEL_2</th>\n",
       "      <th>CLASS_LEVEL_3</th>\n",
       "      <th>CLASS_LEVEL_4</th>\n",
       "      <th>RET_TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3316</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01704</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.094847</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.022351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3316</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01704</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.094847</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.011892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3316</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01704</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.094847</td>\n",
       "      <td>136</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.015285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3316</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01704</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.094847</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.019226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3316</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01704</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.094847</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>0.006644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_DAY   RET_216   RET_238    RET_45  RET_295  RET_230   RET_120  \\\n",
       "ID                                                                     \n",
       "0     3316  0.004024  0.009237  0.004967      NaN  0.01704  0.013885   \n",
       "1     3316  0.004024  0.009237  0.004967      NaN  0.01704  0.013885   \n",
       "2     3316  0.004024  0.009237  0.004967      NaN  0.01704  0.013885   \n",
       "3     3316  0.004024  0.009237  0.004967      NaN  0.01704  0.013885   \n",
       "4     3316  0.004024  0.009237  0.004967      NaN  0.01704  0.013885   \n",
       "\n",
       "     RET_188   RET_260    RET_15  ...   RET_193    RET_95   RET_162   RET_297  \\\n",
       "ID                                ...                                           \n",
       "0   0.041885  0.015207 -0.003143  ... -0.010233  0.001251 -0.003102 -0.094847   \n",
       "1   0.041885  0.015207 -0.003143  ... -0.010233  0.001251 -0.003102 -0.094847   \n",
       "2   0.041885  0.015207 -0.003143  ... -0.010233  0.001251 -0.003102 -0.094847   \n",
       "3   0.041885  0.015207 -0.003143  ... -0.010233  0.001251 -0.003102 -0.094847   \n",
       "4   0.041885  0.015207 -0.003143  ... -0.010233  0.001251 -0.003102 -0.094847   \n",
       "\n",
       "    ID_TARGET  CLASS_LEVEL_1  CLASS_LEVEL_2  CLASS_LEVEL_3  CLASS_LEVEL_4  \\\n",
       "ID                                                                          \n",
       "0         139              0              0              1              1   \n",
       "1         129              6             13             33             53   \n",
       "2         136              6             13             33             53   \n",
       "3         161              3              5             20             32   \n",
       "4         217              4             10             28             47   \n",
       "\n",
       "    RET_TARGET  \n",
       "ID              \n",
       "0    -0.022351  \n",
       "1    -0.011892  \n",
       "2    -0.015285  \n",
       "3    -0.019226  \n",
       "4     0.006644  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_data = imp.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(test_data.columns) + [\"CLASS_LEVEL_1\", \"CLASS_LEVEL_2\", \"CLASS_LEVEL_3\", \"CLASS_LEVEL_4\", \"RET_TARGET\"]\n",
    "train_data = pd.DataFrame(train_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data with Robust Scaler model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(train_data.drop(\"RET_TARGET\", axis=1))\n",
    "scaled_X = scaler.transform(train_data.drop(\"RET_TARGET\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'% of variance explained')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a PCA to have more reliable data\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = PCA()\n",
    "coord = model.fit_transform(scaled_X)\n",
    "\n",
    "plt.plot(np.arange(1, coord.shape[1]+1), np.cumsum(model.explained_variance_ratio_))\n",
    "plt.grid()\n",
    "plt.title(\"Explained variance ratio vs. # of components\")\n",
    "plt.xlabel(\"# of components\")\n",
    "plt.ylabel(\"% of variance explained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "coord_new = SelectKBest(f_classif, k=60).fit_transform(coord, train_data[\"RET_TARGET\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataSet in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(coord_new, train_data[\"RET_TARGET\"], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 94.2min\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed: 334.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier to predict the asset return sign\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = {\"learning_rate\": [.01, .02, .03],\n",
    "              \"n_estimators\": [100, 200, 300],\n",
    "              \"max_depth\": [3, 4, 5]}\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, np.sign(y_train))\n",
    "\n",
    "print(\"Lowest error\", grid.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      147721.9548           18.87m\n",
      "         2      147509.0723           18.72m\n",
      "         3      147301.8103           18.53m\n",
      "         4      147099.9916           18.14m\n",
      "         5      146903.4344           18.01m\n",
      "         6      146711.9901           17.99m\n",
      "         7      146524.8245           17.82m\n",
      "         8      146343.1391           17.62m\n",
      "         9      146165.5036           17.38m\n",
      "        10      145993.0513           17.09m\n",
      "        20      144489.7792           15.07m\n",
      "        30      143324.5225           13.15m\n",
      "        40      142418.8901           11.23m\n",
      "        50      141707.3474            9.35m\n",
      "        60      141150.0701            7.48m\n",
      "        70      140711.2565            5.60m\n",
      "        80      140361.9526            3.73m\n",
      "        90      140079.0616            1.87m\n",
      "       100      139849.6763            0.00s\n",
      "Confusion matrix :\n",
      "[[19462     0  8583]\n",
      " [    1     0     0]\n",
      " [11884     0 13490]]\n",
      "\n",
      "Score :\n",
      "0.6782123761465633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Choosing best model\n",
    "model = GradientBoostingClassifier(learning_rate=0.01, n_estimators=100, \n",
    "                                   max_depth=3, verbose=1)\n",
    "model.fit(X_train, np.sign(y_train))\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Score metric used for the challenge\n",
    "def weighted_accuracy(y_test, y_pred):\n",
    "    y_abs = np.abs(y_test)\n",
    "    norm = y_abs.sum()\n",
    "    score = ((np.sign(y_pred) == np.sign(y_test)) * y_abs).sum() / norm\n",
    "    return score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion matrix :\")\n",
    "print(confusion_matrix(y_true=np.sign(y_test), y_pred=model.predict(X_test)))\n",
    "print()\n",
    "print(\"Score :\")\n",
    "print(weighted_accuracy(y_test, model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
